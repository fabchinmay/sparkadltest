// Databricks notebook source
import org.apache.spark.sql._
import org.apache.spark.sql.types._

val url = "wasbs://data@iomegastorage.blob.core.windows.net/customer-orders.csv"
var orderSchema = StructType(
  Array(
    StructField("userId", IntegerType, true),
    StructField("lineItemId", IntegerType, true),
    StructField("orderAmount", DoubleType, true)))


val data = spark.read.
  option("header","false").
  option("sep",",").
  option("inferSchema", "false").
  schema(orderSchema).
  csv(url)

data.createOrReplaceTempView("orders")


  



// COMMAND ----------

// MAGIC %sql
// MAGIC 
// MAGIC CREATE TABLE ProcessedOrders
// MAGIC   USING PARQUET
// MAGIC   PARTITIONED BY (userId)
// MAGIC   OPTIONS ('compression' = 'snappy')
// MAGIC   AS
// MAGIC   SELECT userId, SUM(orderAmount) AS totalAmount
// MAGIC     FROM orders
// MAGIC     GROUP BY userId
// MAGIC     ORDER BY totalAmount DESC
// MAGIC     LIMIT 10

// COMMAND ----------

